{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcd4bf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier # Import XGBoost\n",
    "import numpy as np # Added for np.sum in fairness metrics\n",
    "# from sklearn.utils.class_weight import compute_sample_weight # Not used in current reweighting logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531f5cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(file_path='fairness-dashboard/data/loan_data.csv'):\n",
    "    \"\"\"\n",
    "    Loads the dataset and performs initial preprocessing steps:\n",
    "    - Maps 'previous_loan_defaults_on_file' to numerical.\n",
    "    - Creates 'age_group' from 'person_age' and drops original.\n",
    "    - Keeps 'person_income' as numerical for normalization later.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (X, y)\n",
    "            X (pd.DataFrame): Features DataFrame before final scaling/encoding.\n",
    "            y (pd.Series): Target Series.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"Dataset loaded successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {file_path} not found. Please ensure the file is in the correct directory.\")\n",
    "        # Create a dummy DataFrame if the file is not found to allow the app to run\n",
    "        data = {\n",
    "            'person_gender': np.random.choice(['male', 'female'], 1000, p=[0.6, 0.4]),\n",
    "            'person_education': np.random.choice(['Bachelor', 'Master', 'High School', 'Associate', 'Doctorate'], 1000),\n",
    "            'person_income': np.random.randint(20000, 150000, 1000),\n",
    "            'person_emp_exp': np.random.randint(0, 20, 1000),\n",
    "            'person_home_ownership': np.random.choice(['RENT', 'OWN', 'MORTGAGE', 'OTHER'], 1000),\n",
    "            'loan_amnt': np.random.randint(1000, 35000, 1000),\n",
    "            'loan_intent': np.random.choice(['PERSONAL', 'EDUCATION', 'MEDICAL', 'VENTURE', 'HOMEIMPROVEMENT', 'DEBTCONSOLIDATION'], 1000),\n",
    "            'loan_int_rate': np.random.uniform(5.0, 20.0, 1000),\n",
    "            'loan_percent_income': np.random.uniform(0.05, 0.5, 1000),\n",
    "            'cb_person_cred_hist_length': np.random.randint(2, 15, 1000),\n",
    "            'credit_score': np.random.randint(500, 800, 1000),\n",
    "            'previous_loan_defaults_on_file': np.random.choice([0, 1], 1000, p=[0.8, 0.2]),\n",
    "            'loan_status': np.random.choice([0, 1], 1000, p=[0.7, 0.3]),\n",
    "            'person_age': np.random.randint(20, 70, 1000)\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "        print(\"Using dummy data as 'loan_data.csv' was not found.\")\n",
    "\n",
    "    print(\"\\n--- Initial Data Info ---\")\n",
    "    df.info()\n",
    "    print(\"\\n--- Missing Values Before Handling ---\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    # 1. Map 'previous_loan_defaults_on_file'\n",
    "    df['previous_loan_defaults_on_file'] = df['previous_loan_defaults_on_file'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "    # 2. Convert 'person_age' to 'age_group' and drop original\n",
    "    bins_age = [0, 18, 30, 45, 60, df['person_age'].max() + 1]\n",
    "    labels_age = ['0-18', '18-30', '30-45', '45-60', '60 and above']\n",
    "    df['age_group'] = pd.cut(df['person_age'], bins=bins_age, labels=labels_age, right=False, include_lowest=True)\n",
    "    df.drop(columns=['person_age'], inplace=True)\n",
    "\n",
    "    X = df.drop('loan_status', axis=1)\n",
    "    y = df['loan_status']\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Execute data loading and initial preprocessing\n",
    "X_raw, y = load_and_preprocess_data()\n",
    "\n",
    "# Split data into training and testing sets (raw, before final scaling/encoding)\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X_raw, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# X_test_for_fairness is needed for fairness metrics, retaining original values\n",
    "X_test_for_fairness = X_test_raw.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d71dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(X_train_raw, X_test_raw):\n",
    "    \"\"\"\n",
    "    Applies Min-Max Scaling to numerical features and One-Hot Encoding to categorical features.\n",
    "    Handles missing values with median for numerical and mode for categorical.\n",
    "\n",
    "    Args:\n",
    "        X_train_raw (pd.DataFrame): Training features before final scaling/encoding.\n",
    "        X_test_raw (pd.DataFrame): Testing features before final scaling/encoding.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (X_train_processed, X_test_processed)\n",
    "            X_train_processed (pd.DataFrame): Fully preprocessed training features.\n",
    "            X_test_processed (pd.DataFrame): Fully preprocessed testing features.\n",
    "    \"\"\"\n",
    "    numerical_features = X_train_raw.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    categorical_features = X_train_raw.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    print(f\"\\nNumerical Features (for normalization): {numerical_features}\")\n",
    "    print(f\"Categorical Features (for one-hot encoding): {categorical_features}\")\n",
    "\n",
    "    # Handle missing numerical values with median before scaling\n",
    "    for col in numerical_features:\n",
    "        median_val = X_train_raw[col].median()\n",
    "        X_train_raw[col] = X_train_raw[col].fillna(median_val)\n",
    "        X_test_raw[col] = X_test_raw[col].fillna(median_val)\n",
    "\n",
    "    # Handle missing categorical values with mode before one-hot encoding\n",
    "    for col in categorical_features:\n",
    "        mode_val = X_train_raw[col].mode()[0]\n",
    "        X_train_raw[col] = X_train_raw[col].fillna(mode_val)\n",
    "        X_test_raw[col] = X_test_raw[col].fillna(mode_val)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    onehot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "    X_train_scaled_num = scaler.fit_transform(X_train_raw[numerical_features])\n",
    "    X_test_scaled_num = scaler.transform(X_test_raw[numerical_features])\n",
    "\n",
    "    X_train_encoded_cat = onehot_encoder.fit_transform(X_train_raw[categorical_features])\n",
    "    X_test_encoded_cat = onehot_encoder.transform(X_test_raw[categorical_features])\n",
    "\n",
    "    X_train_scaled_num_df = pd.DataFrame(X_train_scaled_num, columns=numerical_features, index=X_train_raw.index)\n",
    "    X_test_scaled_num_df = pd.DataFrame(X_test_scaled_num, columns=numerical_features, index=X_test_raw.index)\n",
    "\n",
    "    encoded_feature_names = onehot_encoder.get_feature_names_out(categorical_features)\n",
    "    X_train_encoded_cat_df = pd.DataFrame(X_train_encoded_cat, columns=encoded_feature_names, index=X_train_raw.index)\n",
    "    X_test_encoded_cat_df = pd.DataFrame(X_test_encoded_cat, columns=encoded_feature_names, index=X_test_raw.index)\n",
    "\n",
    "    X_train_processed = pd.concat([X_train_scaled_num_df, X_train_encoded_cat_df], axis=1)\n",
    "    X_test_processed = pd.concat([X_test_scaled_num_df, X_test_encoded_cat_df], axis=1)\n",
    "\n",
    "    print(\"\\n--- Final X_train and X_test Info (after all preprocessing) ---\")\n",
    "    print(\"X_train info:\")\n",
    "    X_train_processed.info()\n",
    "    print(\"\\nX_test info:\")\n",
    "    X_test_processed.info()\n",
    "\n",
    "    return X_train_processed, X_test_processed\n",
    "\n",
    "# Execute feature preprocessing\n",
    "X_train_processed, X_test_processed = preprocess_features(X_train_raw.copy(), X_test_raw.copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8567dedb",
   "metadata": {},
   "source": [
    " Bias Mitigation - Reweighting\n",
    "Reweighting is a pre-processing bias mitigation technique. It works by assigning different weights to individual data samples in the training set. The goal is to balance the representation of different protected groups (and their outcomes) in the training data, so that the model doesn't learn biases present in the original dataset.\n",
    "\n",
    "The weight for each sample (g,y) (where g is the protected group and y is the outcome label) is calculated as:\n",
    "\n",
    "\n",
    "w(g,y)= \n",
    "P(A=g)×P(Y=y∣A=g)\n",
    "P(Y=y)\n",
    "​\n",
    " \n",
    "\n",
    "Where:\n",
    "\n",
    "P(Y=y) is the overall proportion of instances with label y.\n",
    "\n",
    "P(A=g) is the overall proportion of instances in protected group g.\n",
    "\n",
    "P(Y=y∣A=g) is the proportion of instances with label y within group g.\n",
    "\n",
    "This formula effectively up-weights under-represented groups/outcomes and down-weights over-represented ones, aiming for demographic parity (equal positive outcome rates) across groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ab22514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_reweighting(X_train_raw, y_train, protected_attribute_name, positive_outcome_label=1):\n",
    "    \"\"\"\n",
    "    Calculates sample weights for reweighting bias mitigation, aiming for\n",
    "    demographic parity (equal positive outcome rates) across groups of a\n",
    "    single protected attribute.\n",
    "\n",
    "    The weight for each sample (g, y) is calculated as:\n",
    "    w(g, y) = P(Y=y) / (P(A=g) * P(Y=y | A=g))\n",
    "    where:\n",
    "    - P(Y=y) is the overall proportion of instances with label y.\n",
    "    - P(A=g) is the overall proportion of instances in protected group g.\n",
    "    - P(Y=y | A=g) is the proportion of instances with label y within group g.\n",
    "\n",
    "    Args:\n",
    "        X_train_raw (pd.DataFrame): The raw (unprocessed, but with age/income grouped)\n",
    "                                    training features DataFrame.\n",
    "        y_train (pd.Series): The training target labels.\n",
    "        protected_attribute_name (str or list): The name(s) of the protected attribute column(s)\n",
    "                                        (e.g., 'person_gender', ['person_gender', 'age_group']).\n",
    "        positive_outcome_label (int): The label representing the positive outcome (e.g., 1 for approved).\n",
    "\n",
    "    Returns:\n",
    "        np.array: An array of sample weights, one for each sample in X_train_raw.\n",
    "                  Returns None if the protected attribute is not found or has issues.\n",
    "    \"\"\"\n",
    "    # Handle single vs. multiple protected attributes\n",
    "    if isinstance(protected_attribute_name, list):\n",
    "        # Create an intersectional group identifier\n",
    "        if not all(col in X_train_raw.columns for col in protected_attribute_name):\n",
    "            print(f\"Error: One or more protected attributes {protected_attribute_name} not found in X_train_raw.\")\n",
    "            return None\n",
    "        # Convert numerical attributes to binned categories for intersectional grouping\n",
    "        temp_protected_attr_df = X_train_raw[protected_attribute_name].copy()\n",
    "        for col in protected_attribute_name:\n",
    "            if temp_protected_attr_df[col].dtype in ['int64', 'float64']:\n",
    "                bins = pd.cut(temp_protected_attr_df[col], bins=5, right=False, include_lowest=True, duplicates='drop')\n",
    "                temp_protected_attr_df[col] = bins\n",
    "        prot_attr_series = temp_protected_attr_df.astype(str).agg('-'.join, axis=1)\n",
    "    else:\n",
    "        if protected_attribute_name not in X_train_raw.columns:\n",
    "            print(f\"Error: Protected attribute '{protected_attribute_name}' not found in X_train_raw.\")\n",
    "            return None\n",
    "        prot_attr_series = X_train_raw[protected_attribute_name]\n",
    "        if prot_attr_series.dtype in ['int64', 'float64']:\n",
    "            bins = pd.cut(prot_attr_series, bins=5, right=False, include_lowest=True, duplicates='drop')\n",
    "            prot_attr_series = bins\n",
    "\n",
    "    print(f\"\\n--- Applying Reweighting for Protected Attribute(s): '{protected_attribute_name}' ---\")\n",
    "\n",
    "    # Combine X_train_raw and y_train for easier group-wise calculations\n",
    "    train_data = X_train_raw.copy()\n",
    "    train_data['target'] = y_train\n",
    "    train_data['prot_attr_group'] = prot_attr_series.values # Align with train_data index\n",
    "\n",
    "    # Calculate overall proportions\n",
    "    p_y = train_data['target'].value_counts(normalize=True)\n",
    "\n",
    "    # Calculate group proportions\n",
    "    p_g = train_data['prot_attr_group'].value_counts(normalize=True)\n",
    "\n",
    "    # Calculate conditional proportions P(Y=y | A=g)\n",
    "    p_y_given_g = train_data.groupby('prot_attr_group')['target'].value_counts(normalize=True)\n",
    "\n",
    "    sample_weights = np.zeros(len(train_data))\n",
    "\n",
    "    # Iterate through each sample to assign a weight\n",
    "    for i, row in train_data.iterrows():\n",
    "        group = row['prot_attr_group'] # Get the group for the current sample\n",
    "        label = row['target']\n",
    "\n",
    "        p_y_val = p_y.get(label, 0.0)\n",
    "        p_g_val = p_g.get(group, 0.0)\n",
    "        p_y_given_g_val = p_y_given_g.get((group, label), 0.0)\n",
    "\n",
    "        if p_g_val > 0 and p_y_given_g_val > 0:\n",
    "            weight = p_y_val / (p_g_val * p_y_given_g_val)\n",
    "        else:\n",
    "            weight = 1.0 # Default to no reweighting if calculation is not possible for a specific instance\n",
    "\n",
    "        sample_weights[train_data.index.get_loc(i)] = weight\n",
    "\n",
    "    # Normalize weights to prevent them from overly influencing the loss function magnitude\n",
    "    # This is a common practice to keep the sum of weights equal to the number of samples\n",
    "    sample_weights = sample_weights / np.sum(sample_weights) * len(sample_weights)\n",
    "\n",
    "    print(f\"Reweighting applied. Sample weights calculated for '{protected_attribute_name}'.\")\n",
    "    print(f\"  First 5 sample weights: {sample_weights[:5]}\")\n",
    "    print(f\"  Sum of sample weights: {np.sum(sample_weights)}\")\n",
    "    print(f\"  Min sample weight: {np.min(sample_weights)}, Max sample weight: {np.max(sample_weights)}\")\n",
    "    return sample_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce20c64b",
   "metadata": {},
   "source": [
    " Model Training and Evaluation\n",
    "This section defines a function to train and evaluate several common classification models. We will use:\n",
    "\n",
    "Logistic Regression: A linear model for binary classification.\n",
    "\n",
    "Decision Tree: A non-linear model that makes decisions based on feature values.\n",
    "\n",
    "Random Forest: An ensemble method that builds multiple decision trees and merges their predictions.\n",
    "\n",
    "XGBoost: A powerful gradient boosting framework known for its performance and speed.\n",
    "\n",
    "Each model is trained on the preprocessed data, and its performance is assessed using:\n",
    "\n",
    "Accuracy: The proportion of correctly classified instances.\n",
    "\n",
    "Classification Report: Provides Precision, Recall, and F1-score for each class (0 and 1), and their averages.\n",
    "\n",
    "Precision: The proportion of positive identifications that were actually correct.\n",
    "\n",
    "Recall (Sensitivity): The proportion of actual positives that were identified correctly.\n",
    "\n",
    "F1-score: The harmonic mean of Precision and Recall, providing a balance between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ecf050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(X_train, y_train, X_test, y_test, models_dict, sample_weights=None):\n",
    "    \"\"\"\n",
    "    Trains specified binary classification models and evaluates their performance.\n",
    "    Can apply sample weights during training.\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Preprocessed training features.\n",
    "        y_train (pd.Series): Training target.\n",
    "        X_test (pd.DataFrame): Preprocessed testing features.\n",
    "        y_test (pd.Series): Testing target.\n",
    "        models_dict (dict): Dictionary of model names and scikit-learn model instances.\n",
    "        sample_weights (np.array, optional): Array of sample weights for training.\n",
    "                                            Defaults to None (no reweighting).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing results for each model, including accuracy,\n",
    "              classification report, trained model, and predictions.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    print(\"\\n--- Model Training and Evaluation ---\")\n",
    "    for name, model in models_dict.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        try:\n",
    "            # Directly attempt to fit with sample_weight if provided\n",
    "            if sample_weights is not None:\n",
    "                model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "                print(f\"  {name} trained WITH sample weights.\")\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "                print(f\"  {name} trained WITHOUT sample weights (sample_weights was None).\")\n",
    "        except TypeError as e:\n",
    "            # Fallback if the model genuinely does not support sample_weight\n",
    "            print(f\"  Warning: {name} does not support sample_weight. Training without it. Error: {e}\")\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # --- DIAGNOSTIC PRINT: Check predicted class distribution ---\n",
    "        print(f\"  {name} Predicted Class Distribution on Test Set:\")\n",
    "        print(pd.Series(y_pred).value_counts())\n",
    "        print(\"-\" * 40)\n",
    "        # -----------------------------------------------------------\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "        results[name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'classification_report': report,\n",
    "            'model': model,\n",
    "            'y_pred': y_pred\n",
    "        }\n",
    "        print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"{name} Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "    print(\"\\n--- Summary of Model Accuracies ---\")\n",
    "    for name, res in results.items():\n",
    "        print(f\"{name}: Accuracy = {res['accuracy']:.4f}\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f850672e",
   "metadata": {},
   "source": [
    "Fairness Metrics Calculation\n",
    "Beyond overall accuracy, it's crucial to assess if a model's performance is fair across different demographic groups. We calculate the following fairness metrics:\n",
    "\n",
    "Proportion of Positive Predictions (PPR): The proportion of individuals in a specific group who received a positive prediction (e.g., loan approved).\n",
    "\n",
    "True Positive Rate (TPR) / Recall: The proportion of actual positive cases within a group that were correctly identified as positive. This is also known as \"Equal Opportunity.\"\n",
    "\n",
    "From these, we derive two key fairness indicators:\n",
    "\n",
    "Disparate Impact Ratio (DIR):\n",
    "\n",
    "\n",
    "DIR= \n",
    "PPR \n",
    "privileged\n",
    "​\n",
    " \n",
    "PPR \n",
    "unprivileged\n",
    "​\n",
    " \n",
    "​\n",
    " \n",
    "\n",
    "An ideal DIR is 1.0, meaning the positive prediction rate is equal for both groups. A value significantly below 1 (e.g., < 0.8) indicates that the unprivileged group is less likely to receive a positive outcome. A value significantly above 1 (e.g., > 1.25) indicates the unprivileged group is more likely to receive a positive outcome.\n",
    "\n",
    "Equal Opportunity Difference (EOD):\n",
    "\n",
    "\n",
    "EOD=TPR \n",
    "privileged\n",
    "​\n",
    " −TPR \n",
    "unprivileged\n",
    "​\n",
    " \n",
    "\n",
    "An ideal EOD is 0.0, meaning the True Positive Rate is equal for both groups. This implies that the model is equally effective at identifying positive cases across different groups.\n",
    "\n",
    "We define \"privileged\" and \"unprivileged\" groups based on their population size (majority vs. minority) for the purpose of calculating these ratios and differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7027efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_disparate_impact_ratio(group_metrics, privileged_group, unprivileged_group):\n",
    "    \"\"\"\n",
    "    Calculates the Disparate Impact Ratio given group metrics and group labels.\n",
    "    Returns the ratio and a message if calculation is not possible.\n",
    "    \"\"\"\n",
    "    ppr_privileged = group_metrics.get(privileged_group, {}).get('PPR', 0.0)\n",
    "    ppr_unprivileged = group_metrics.get(unprivileged_group, {}).get('PPR', 0.0)\n",
    "    if ppr_privileged > 0:\n",
    "        return ppr_unprivileged / ppr_privileged, None\n",
    "    else:\n",
    "        return None, \"Disparate Impact Ratio: Cannot calculate (privileged group PPR is zero).\"\n",
    "\n",
    "def calculate_equal_opportunity_difference(group_metrics, privileged_group, unprivileged_group):\n",
    "    \"\"\"\n",
    "    Calculates the Equal Opportunity Difference given group metrics and group labels.\n",
    "    Returns the difference and a message if calculation is not possible.\n",
    "    \"\"\"\n",
    "    tpr_privileged = group_metrics.get(privileged_group, {}).get('TPR', 0.0)\n",
    "    tpr_unprivileged = group_metrics.get(unprivileged_group, {}).get('TPR', 0.0)\n",
    "    if group_metrics.get(privileged_group, {}).get('Actual Positives', 0) > 0 and \\\n",
    "       group_metrics.get(unprivileged_group, {}).get('Actual Positives', 0) > 0:\n",
    "        return tpr_privileged - tpr_unprivileged, None\n",
    "    else:\n",
    "        return None, \"Equal Opportunity Difference: Not enough groups with actual positives to compare for the selected privileged/unprivileged groups.\"\n",
    "\n",
    "\n",
    "def calculate_fairness_metrics(results, y_test, X_test_for_fairness, protected_attributes, positive_outcome_label=1, strategy_label='Standard'):\n",
    "    \"\"\"\n",
    "    Calculates and prints Disparate Impact Ratio and Equal Opportunity Difference\n",
    "    for each model across specified protected attributes, defining privileged/unprivileged\n",
    "    based on majority/minority population.\n",
    "\n",
    "    Args:\n",
    "        results (dict): Dictionary containing model results (predictions, etc.).\n",
    "        y_test (pd.Series): True labels for the test set.\n",
    "        X_test_for_fairness (pd.DataFrame): Test features with original protected attributes.\n",
    "        protected_attributes (list): List of column names to treat as protected attributes.\n",
    "        positive_outcome_label (int/str): The label representing the positive outcome.\n",
    "        strategy_label (str): Label indicating the mitigation strategy (e.g., 'Standard', 'Reweighted').\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing calculated fairness metrics for dashboard visualization.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Fairness Metrics Calculation for Strategy: {strategy_label} ---\")\n",
    "    fairness_data = [] # To store data for dashboard\n",
    "\n",
    "    for model_name, model_results in results.items():\n",
    "        # Add overall accuracy to fairness_data\n",
    "        fairness_data.append({\n",
    "            'Model': model_name,\n",
    "            'Strategy': strategy_label,\n",
    "            'Protected Attribute': 'Overall',\n",
    "            'Group': 'Overall',\n",
    "            'Metric Type': 'Accuracy',\n",
    "            'Value': model_results['accuracy']\n",
    "        })\n",
    "\n",
    "        # Add macro-averaged Precision, Recall, and F1-Score\n",
    "        macro_avg_report = model_results['classification_report']['macro avg']\n",
    "        fairness_data.append({\n",
    "            'Model': model_name,\n",
    "            'Strategy': strategy_label,\n",
    "            'Protected Attribute': 'Overall',\n",
    "            'Group': 'Overall',\n",
    "            'Metric Type': 'Precision (Macro Avg)',\n",
    "            'Value': macro_avg_report['precision']\n",
    "        })\n",
    "        fairness_data.append({\n",
    "            'Model': model_name,\n",
    "            'Strategy': strategy_label,\n",
    "            'Protected Attribute': 'Overall',\n",
    "            'Group': 'Overall',\n",
    "            'Metric Type': 'Recall (Macro Avg)',\n",
    "            'Value': macro_avg_report['recall']\n",
    "        })\n",
    "        fairness_data.append({\n",
    "            'Model': model_name,\n",
    "            'Strategy': strategy_label,\n",
    "            'Protected Attribute': 'Overall',\n",
    "            'Group': 'Overall',\n",
    "            'Metric Type': 'F1-Score (Macro Avg)',\n",
    "            'Value': macro_avg_report['f1-score']\n",
    "        })\n",
    "\n",
    "\n",
    "        y_pred = model_results['y_pred']\n",
    "\n",
    "        for attr in protected_attributes:\n",
    "            if attr not in X_test_for_fairness.columns:\n",
    "                print(f\"Warning: Protected attribute '{attr}' not found in X_test_for_fairness. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\n  Protected Attribute: {attr}\")\n",
    "\n",
    "            # Determine groups and their population sizes\n",
    "            if X_test_for_fairness[attr].dtype in ['int64', 'float64']:\n",
    "                temp_attr_series = pd.cut(X_test_for_fairness[attr], bins=5, labels=[f'{attr} Group {i+1}' for i in range(5)], right=False, include_lowest=True, duplicates='drop')\n",
    "                group_populations = temp_attr_series.value_counts()\n",
    "                groups = sorted(pd.Series(temp_attr_series.unique()).dropna().tolist())\n",
    "            else:\n",
    "                group_populations = X_test_for_fairness[attr].value_counts()\n",
    "                groups = sorted(pd.Series(X_test_for_fairness[attr].unique()).dropna().tolist())\n",
    "\n",
    "            if len(groups) < 2:\n",
    "                print(f\"    Only one group found for '{attr}'. Cannot calculate fairness metrics.\")\n",
    "                continue\n",
    "\n",
    "            valid_groups = [g for g in groups if g in group_populations and group_populations[g] > 0]\n",
    "\n",
    "            if len(valid_groups) < 2:\n",
    "                print(f\"    Not enough valid groups with samples for '{attr}'. Cannot calculate fairness metrics.\")\n",
    "                continue\n",
    "\n",
    "            privileged_group_pop = group_populations[valid_groups].idxmax()\n",
    "            unprivileged_group_pop = group_populations[valid_groups].idxmin()\n",
    "\n",
    "            group_metrics = {}\n",
    "\n",
    "            for group in groups:\n",
    "                if X_test_for_fairness[attr].dtype in ['int64', 'float64']:\n",
    "                    group_mask = (temp_attr_series == group)\n",
    "                else:\n",
    "                    group_mask = (X_test_for_fairness[attr] == group)\n",
    "\n",
    "                y_true_group = y_test[group_mask]\n",
    "                y_pred_group = y_pred[group_mask]\n",
    "\n",
    "                if len(y_true_group) == 0:\n",
    "                    print(f\"    Group '{group}' has no samples in the test set. Skipping metric calculation for this group.\")\n",
    "                    continue\n",
    "\n",
    "                tn, fp, fn, tp = confusion_matrix(y_true_group, y_pred_group, labels=[0, 1]).ravel()\n",
    "\n",
    "                total_group_predictions = len(y_pred_group)\n",
    "                ppr = tp + fp\n",
    "                ppr_rate = ppr / total_group_predictions if total_group_predictions > 0 else 0\n",
    "\n",
    "                actual_positives_in_group = tp + fn\n",
    "                tpr = tp / actual_positives_in_group if actual_positives_in_group > 0 else 0\n",
    "\n",
    "                group_metrics[group] = {\n",
    "                    'PPR': ppr_rate,\n",
    "                    'TPR': tpr,\n",
    "                    'TP': tp,\n",
    "                    'FP': fp,\n",
    "                    'FN': fn,\n",
    "                    'TN': tn,\n",
    "                    'Total Samples': total_group_predictions,\n",
    "                    'Actual Positives': actual_positives_in_group\n",
    "                }\n",
    "                print(f\"    Group '{group}': PPR = {ppr_rate:.4f}, TPR = {tpr:.4f} (Population: {len(y_true_group)})\")\n",
    "\n",
    "                # Add individual group PPR and TPR to fairness_data\n",
    "                fairness_data.append({\n",
    "                    'Model': model_name,\n",
    "                    'Strategy': strategy_label,\n",
    "                    'Protected Attribute': attr,\n",
    "                    'Group': str(group),\n",
    "                    'Metric Type': 'PPR',\n",
    "                    'Value': ppr_rate\n",
    "                })\n",
    "                fairness_data.append({\n",
    "                    'Model': model_name,\n",
    "                    'Strategy': strategy_label,\n",
    "                    'Protected Attribute': attr,\n",
    "                    'Group': str(group),\n",
    "                    'Metric Type': 'TPR',\n",
    "                    'Value': tpr\n",
    "                })\n",
    "\n",
    "\n",
    "            # Disparate Impact Ratio\n",
    "            disparate_impact_ratio, dir_msg = calculate_disparate_impact_ratio(group_metrics, privileged_group_pop, unprivileged_group_pop)\n",
    "            if disparate_impact_ratio is not None:\n",
    "                print(f\"    Disparate Impact Ratio (PPR_{unprivileged_group_pop} / PPR_{privileged_group_pop}): {disparate_impact_ratio:.4f}\")\n",
    "                fairness_data.append({\n",
    "                    'Model': model_name,\n",
    "                    'Strategy': strategy_label,\n",
    "                    'Protected Attribute': attr,\n",
    "                    'Group': f'DI ({unprivileged_group_pop} vs {privileged_group_pop})',\n",
    "                    'Metric Type': 'Disparate Impact Ratio',\n",
    "                    'Value': disparate_impact_ratio\n",
    "                })\n",
    "            else:\n",
    "                print(f\"    {dir_msg}\")\n",
    "                fairness_data.append({\n",
    "                    'Model': model_name,\n",
    "                    'Strategy': strategy_label,\n",
    "                    'Protected Attribute': attr,\n",
    "                    'Group': f'DI ({unprivileged_group_pop} vs {privileged_group_pop})',\n",
    "                    'Metric Type': 'Disparate Impact Ratio',\n",
    "                    'Value': np.nan\n",
    "                })\n",
    "\n",
    "\n",
    "            # Equal Opportunity Difference\n",
    "            equal_opportunity_diff, eod_msg = calculate_equal_opportunity_difference(group_metrics, privileged_group_pop, unprivileged_group_pop)\n",
    "            if equal_opportunity_diff is not None:\n",
    "                print(f\"    Equal Opportunity Difference (TPR_{privileged_group_pop} - TPR_{unprivileged_group_pop}): {equal_opportunity_diff:.4f}\")\n",
    "                fairness_data.append({\n",
    "                    'Model': model_name,\n",
    "                    'Strategy': strategy_label,\n",
    "                    'Protected Attribute': attr,\n",
    "                    'Group': f'EO ({privileged_group_pop} - {unprivileged_group_pop})',\n",
    "                    'Metric Type': 'Equal Opportunity Difference',\n",
    "                    'Value': equal_opportunity_diff\n",
    "                })\n",
    "            else:\n",
    "                print(f\"    {eod_msg}\")\n",
    "                fairness_data.append({\n",
    "                    'Model': model_name,\n",
    "                    'Strategy': strategy_label,\n",
    "                    'Protected Attribute': attr,\n",
    "                    'Group': f'EO ({privileged_group_pop} - {unprivileged_group_pop})',\n",
    "                    'Metric Type': 'Equal Opportunity Difference',\n",
    "                    'Value': np.nan\n",
    "                })\n",
    "    return pd.DataFrame(fairness_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a28fe5",
   "metadata": {},
   "source": [
    " Main Execution Flow\n",
    "This section orchestrates the entire pipeline:\n",
    "\n",
    "Defines the machine learning models to be used.\n",
    "\n",
    "Specifies the protected attributes for fairness analysis.\n",
    "\n",
    "Executes the data preprocessing steps.\n",
    "\n",
    "Trains and evaluates models without any bias mitigation (Standard approach).\n",
    "\n",
    "Calculates fairness metrics for the standard models.\n",
    "\n",
    "Applies the reweighting bias mitigation strategy and then trains and evaluates models with reweighting.\n",
    "\n",
    "Calculates fairness metrics for the reweighted models.\n",
    "\n",
    "Combines all fairness metrics into a single DataFrame and saves it as a Parquet file (combined_fairness_metrics.parquet). This file will be used by the interactive dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1124b758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reweight_and_evaluate_models(\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    models_dict,\n",
    "    protected_attribute,\n",
    "    X_train_for_fairness=None,\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains specified binary classification models with sample reweighting for bias mitigation.\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Preprocessed training features.\n",
    "        y_train (pd.Series): Training target.\n",
    "        X_test (pd.DataFrame): Preprocessed testing features.\n",
    "        y_test (pd.Series): Testing target.\n",
    "        models_dict (dict): Dictionary of model names and scikit-learn model instances.\n",
    "        protected_attribute (str or list): Column name or list of column names in X_train (or X_train_for_fairness) to use for reweighting.\n",
    "        X_train_for_fairness (pd.DataFrame, optional): DataFrame with original protected attributes (if X_train is encoded).\n",
    "        verbose (bool): If True, prints accuracy and classification report.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing results for each model, including accuracy,\n",
    "              classification report, trained model, and predictions.\n",
    "    \"\"\"\n",
    "    # Use X_train_for_fairness if provided, else X_train\n",
    "    if X_train_for_fairness is not None:\n",
    "        if isinstance(protected_attribute, list):\n",
    "            prot_attr = X_train_for_fairness[protected_attribute].astype(str).agg('-'.join, axis=1)\n",
    "        else:\n",
    "            prot_attr = X_train_for_fairness[protected_attribute]\n",
    "    else:\n",
    "        if isinstance(protected_attribute, list):\n",
    "            prot_attr = X_train[protected_attribute].astype(str).agg('-'.join, axis=1)\n",
    "        else:\n",
    "            prot_attr = X_train[protected_attribute]\n",
    "\n",
    "    # Ensure prot_attr is a pandas Series (important for .value_counts() and .map())\n",
    "    if not isinstance(prot_attr, pd.Series):\n",
    "        prot_attr = pd.Series(prot_attr)\n",
    "\n",
    "    # Compute sample weights inversely proportional to group sizes\n",
    "    group_counts = prot_attr.value_counts()\n",
    "    \n",
    "    # Create a Series of weights where index is the group value and value is 1.0 / count\n",
    "    # Handle cases where a group count might be zero by setting weight to 0 (or a small number)\n",
    "    weights_series = 1.0 / group_counts\n",
    "    weights_series = weights_series.replace([np.inf, -np.inf], 0) # Replace inf/-inf (from 1/0) with 0\n",
    "\n",
    "    # Map these weights back to the original prot_attr Series to get sample_weights for each instance\n",
    "    sample_weights = prot_attr.map(weights_series)\n",
    "\n",
    "    # Handle any NaN values that might occur if a group in prot_attr was not in group_counts\n",
    "    # (e.g., if it was a NaN that got dropped by value_counts, or if it was a group with 0 count)\n",
    "    # Defaulting to 1.0 means no reweighting for such instances.\n",
    "    sample_weights = sample_weights.fillna(1.0)\n",
    "\n",
    "    # Normalize weights to prevent them from overly influencing the loss function magnitude\n",
    "    sample_weights = sample_weights / np.sum(sample_weights) * len(sample_weights)\n",
    "\n",
    "    results = {}\n",
    "    print(\"\\n--- Model Training and Evaluation with Reweighting ---\")\n",
    "    for name, model in models_dict.items():\n",
    "        print(f\"\\nTraining {name} with reweighting...\")\n",
    "        try:\n",
    "            # Directly attempt to fit with sample_weight if provided\n",
    "            if sample_weights is not None:\n",
    "                model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "                print(f\"  {name} trained WITH sample weights.\")\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "                print(f\"  {name} trained WITHOUT sample weights (sample_weights was None).\")\n",
    "        except TypeError as e:\n",
    "            # Fallback if the model genuinely does not support sample_weight\n",
    "            print(f\"  Warning: {name} does not support sample_weight. Training without it. Error: {e}\")\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "        results[name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'classification_report': report,\n",
    "            'model': model,\n",
    "            'y_pred': y_pred,\n",
    "            'sample_weights': sample_weights\n",
    "        }\n",
    "        if verbose:\n",
    "            print(f\"{name} Accuracy (reweighted): {accuracy:.4f}\")\n",
    "            print(f\"{name} Classification Report (reweighted):\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "    print(\"\\n--- Summary of Model Accuracies (Reweighted) ---\")\n",
    "    for name, res in results.items():\n",
    "        print(f\"{name}: Accuracy (reweighted) = {res['accuracy']:.4f}\")\n",
    "    return results\n",
    "\n",
    "# Define models to be used\n",
    "selected_models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, solver='liblinear'),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Define protected attributes for fairness analysis\n",
    "protected_attributes_list = ['person_gender', 'age_group', 'person_education', 'person_home_ownership']\n",
    "\n",
    "# 3. Train and evaluate models (standard)\n",
    "print(\"\\n================ Standard Model Training ================\" )\n",
    "model_results = train_and_evaluate_models(X_train_processed, y_train, X_test_processed, y_test, selected_models)\n",
    "print(\"\\n================ Fairness Metrics (Standard) ================\" )\n",
    "fairness_df_standard = calculate_fairness_metrics(model_results, y_test, X_test_for_fairness, protected_attributes_list, strategy_label='Standard')\n",
    "\n",
    "# 4. Train and evaluate models with reweighting (intersectional example)\n",
    "print(\"\\n================ Reweighted Model Training (Intersectional: All Attributes) ================\" )\n",
    "reweighted_model_results_intersectional = reweight_and_evaluate_models(\n",
    "    X_train_processed, y_train, X_test_processed, y_test,\n",
    "    selected_models,\n",
    "    protected_attribute=protected_attributes_list,\n",
    "    X_train_for_fairness=X_train_raw\n",
    ")\n",
    "print(\"\\n================ Fairness Metrics (Reweighted: Intersectional) ================\" )\n",
    "fairness_df_reweighted = calculate_fairness_metrics(reweighted_model_results_intersectional, y_test, X_test_for_fairness, protected_attributes_list, strategy_label='Reweighted')\n",
    "\n",
    "# Combine dataframes for dashboard\n",
    "combined_fairness_df = pd.concat([fairness_df_standard, fairness_df_reweighted], ignore_index=True)\n",
    "print(\"\\nCombined Fairness Data for Dashboard:\")\n",
    "print(combined_fairness_df.head())\n",
    "print(combined_fairness_df.tail())\n",
    "\n",
    "# Save the combined DataFrame to a Parquet file\n",
    "output_file = 'combined_fairness_metrics.parquet'\n",
    "combined_fairness_df.to_parquet(output_file, index=False)\n",
    "print(f\"\\nCombined fairness metrics saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
